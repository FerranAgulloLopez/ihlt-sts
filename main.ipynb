{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Textual Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Adrián Tormos Llorente and Ferran Agulló López"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ferran/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.wsd import lesk\n",
    "from nltk import pos_tag\n",
    "\n",
    "# required downloads\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_values_file(path, array):\n",
    "    with open(path) as f:\n",
    "        data = f.read()\n",
    "        splitted_data = re.split('\\n+', data) # split raw data by tabs and end of lines\n",
    "        if splitted_data[-1] == '':\n",
    "            del splitted_data[-1] # delete last list empty value caused by splitting the last end of line\n",
    "        for pair in splitted_data:\n",
    "            sentence1, sentence2 = pair.split('\\t')\n",
    "            array.append((sentence1, sentence2))\n",
    "    return array\n",
    "\n",
    "def load_labels_file(path, array):\n",
    "    with open(path) as f:\n",
    "        data = f.read()\n",
    "        splitted_data = re.split('\\n+', data) # split raw data by tabs and end of lines\n",
    "        if splitted_data[-1] == '':\n",
    "            del splitted_data[-1] # delete last list empty value caused by splitting the last end of line\n",
    "        for score in splitted_data:\n",
    "            array.append(float(score))\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train values length: 2234 ; Train labels length: 2234\n"
     ]
    }
   ],
   "source": [
    "train_values = []\n",
    "train_labels = []\n",
    "train_path = './input/train'\n",
    "\n",
    "train_values = load_values_file(train_path + '/STS.input.MSRpar.txt', train_values)\n",
    "train_values = load_values_file(train_path + '/STS.input.MSRvid.txt', train_values)\n",
    "train_values = load_values_file(train_path + '/STS.input.SMTeuroparl.txt', train_values)\n",
    "\n",
    "train_labels = load_labels_file(train_path + '/STS.gs.MSRpar.txt', train_labels)\n",
    "train_labels = load_labels_file(train_path + '/STS.gs.MSRvid.txt', train_labels)\n",
    "train_labels = load_labels_file(train_path + '/STS.gs.SMTeuroparl.txt', train_labels)\n",
    "\n",
    "print('Train values length:', len(train_values), '; Train labels length:', len(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test values length: 3108 ; Test labels length: 3108\n"
     ]
    }
   ],
   "source": [
    "test_values = []\n",
    "test_labels = []\n",
    "test_path = './input/test-gold'\n",
    "\n",
    "test_values = load_values_file(test_path + '/STS.input.MSRpar.txt', test_values)\n",
    "test_values = load_values_file(test_path + '/STS.input.MSRvid.txt', test_values)\n",
    "test_values = load_values_file(test_path + '/STS.input.SMTeuroparl.txt', test_values)\n",
    "test_values = load_values_file(test_path + '/STS.input.surprise.OnWN.txt', test_values)\n",
    "test_values = load_values_file(test_path + '/STS.input.surprise.SMTnews.txt', test_values)\n",
    "\n",
    "test_labels = load_labels_file(test_path + '/STS.gs.MSRpar.txt', test_labels)\n",
    "test_labels = load_labels_file(test_path + '/STS.gs.MSRvid.txt', test_labels)\n",
    "test_labels = load_labels_file(test_path + '/STS.gs.SMTeuroparl.txt', test_labels)\n",
    "test_labels = load_labels_file(test_path + '/STS.gs.surprise.OnWN.txt', test_labels)\n",
    "test_labels = load_labels_file(test_path + '/STS.gs.surprise.SMTnews.txt', test_labels)\n",
    "\n",
    "print('Test values length:', len(test_values), '; Test labels length:', len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blablabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we define some functions to increase the legiility of the following code. We know that doing these steps in different functions is not optimal, because we read multiple times the dataset. However, we think it is not important considering the little amount of data and that this exercise it is just a practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the more common punctuation symbols\n",
    "punctuation_set = set(string.punctuation)\n",
    "punctuation_set.add('``')\n",
    "punctuation_set.add('\\'\\'')\n",
    "# Load english stop words\n",
    "sw_set = set(nltk.corpus.stopwords.words('english'))\n",
    "# Create lemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(sentence):\n",
    "    # pre: the sentence in one string\n",
    "    return sentence.lower()\n",
    "\n",
    "def word_tokenize(sentence):\n",
    "    # pre: the sentence in one string\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "def punctuation_removal(tokens):\n",
    "    output = []\n",
    "    for token in tokens:\n",
    "        if token not in punctuation_set:\n",
    "            output.append(token)\n",
    "    return output\n",
    "\n",
    "def stopwords_removal(tokens):\n",
    "    output = []\n",
    "    for token in tokens:\n",
    "        if token not in sw_set:\n",
    "            output.append(token)\n",
    "    return output\n",
    "\n",
    "def pos_tagging(tokens):\n",
    "    pairs = pos_tag(tokens)\n",
    "    tags = [tag for token, tag in pairs]\n",
    "    return tags\n",
    "\n",
    "def lemmatization(tokens, tags):\n",
    "    # post: return the input list of tokens replacing them if possible by their lemmas\n",
    "    output = []\n",
    "    for index, token in enumerate(tokens):\n",
    "        tag = tags[index]\n",
    "        try:\n",
    "            output.append(wnl.lemmatize(token, pos=tag[0].lower()))\n",
    "        except:\n",
    "            output.append(token)\n",
    "    return output\n",
    "\n",
    "def word_sense_disambiguation(tokens, tags):\n",
    "    # post: return the input list of tokens replacing them if possible by their synsets disambiguated\n",
    "    output = []\n",
    "    for index, token in enumerate(tokens):\n",
    "        tag = tags[index]\n",
    "        synset = lesk(tokens, token, tag[0].lower())\n",
    "        if synset is None:\n",
    "            output.append(token)\n",
    "        else:\n",
    "            output.append(synset)\n",
    "    return output\n",
    "\n",
    "def run(sentence, steps):\n",
    "    # pre: the sentence in one string\n",
    "    tokens = None\n",
    "    tags = None\n",
    "    for step in steps:\n",
    "        if step == 'word_tokenization':\n",
    "            tokens = word_tokenize(sentence)\n",
    "        elif step == 'punctuation_removal':\n",
    "            tokens = punctuation_removal(tokens)\n",
    "        elif step == 'stopwords_removal':\n",
    "            tokens = stopwords_removal(tokens)\n",
    "        elif step == 'pos_tagging':\n",
    "            tags = pos_tagging(tokens)\n",
    "        elif step == 'lemmatization':\n",
    "            tokens = lemmatization(tokens, tags)\n",
    "        elif step == 'word_sense_disambiguation':\n",
    "            tokens = word_sense_disambiguation(tokens, tags)\n",
    "    return tokens, tags\n",
    "    \n",
    "def do_pipeline(sentence_pairs, steps):\n",
    "    output = []\n",
    "    for pair in sentence_pairs:\n",
    "        sentence1, sentence2 = pair\n",
    "        tokens1, tags1 = run(sentence1, steps)\n",
    "        tokens2, tags2 = run(sentence2, steps)\n",
    "        if tags1 is not None:\n",
    "            output.append(((tokens1, tags1), (tokens2, tags2)))\n",
    "        else:\n",
    "            output.append((tokens1, tokens2))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_sentence(original_sentence, processed_sentence, tags):\n",
    "    print('\\nSentence')\n",
    "    print('Original:', original_sentence)\n",
    "    if tags:\n",
    "        print('Tags:', processed_sentence[0])\n",
    "        print('Tokens:', processed_sentence[1])\n",
    "    else:\n",
    "        print('Tokens:', processed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the sentences by blanks, delete the punctuation symbols, do postagging and lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = ['word_tokenization', 'punctuation_removal', 'pos_tagging', 'lemmatization']\n",
    "tags = True\n",
    "train_output = do_pipeline(train_values, steps)\n",
    "test_output = do_pipeline(test_values, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show some sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence\n",
      "Original: But other sources close to the sale said Vivendi was keeping the door open to further bids and hoped to see bidders interested in individual assets team up.\n",
      "Tags: ['But', 'other', 'source', 'close', 'to', 'the', 'sale', 'say', 'Vivendi', 'be', 'keep', 'the', 'door', 'open', 'to', 'further', 'bid', 'and', 'hop', 'to', 'see', 'bidder', 'interested', 'in', 'individual', 'asset', 'team', 'up']\n",
      "Tokens: ['CC', 'JJ', 'NNS', 'RB', 'TO', 'DT', 'NN', 'VBD', 'NNP', 'VBD', 'VBG', 'DT', 'NN', 'JJ', 'TO', 'JJ', 'NNS', 'CC', 'VBD', 'TO', 'VB', 'NNS', 'JJ', 'IN', 'JJ', 'NNS', 'VBP', 'RP']\n",
      "\n",
      "Sentence\n",
      "Original: But other sources close to the sale said Vivendi was keeping the door open for further bids in the next day or two.\n",
      "Tags: ['But', 'other', 'source', 'close', 'to', 'the', 'sale', 'say', 'Vivendi', 'be', 'keep', 'the', 'door', 'open', 'for', 'further', 'bid', 'in', 'the', 'next', 'day', 'or', 'two']\n",
      "Tokens: ['CC', 'JJ', 'NNS', 'RB', 'TO', 'DT', 'NN', 'VBD', 'NNP', 'VBD', 'VBG', 'DT', 'NN', 'JJ', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'JJ', 'NN', 'CC', 'CD']\n"
     ]
    }
   ],
   "source": [
    "pretty_print_sentence(train_values[0][0], train_output[0][0], tags)\n",
    "pretty_print_sentence(train_values[0][1], train_output[0][1], tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the similarity with the Jaccard similarity metric for the different pairs of sentences of the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_distance(list1, list2): # it is symmetric\n",
    "    return jaccard_distance(set(list1),set(list2)) # from nltk\n",
    "\n",
    "def compute_jaccard_similarity(list1, list2): # it is symmetric\n",
    "    return 1 - compute_jaccard_distance(list1, list2)\n",
    "\n",
    "def compute_pair_comparison(pairs, tags):\n",
    "    output = np.zeros(len(pairs))\n",
    "    for index, pair in enumerate(pairs):\n",
    "        if tags:\n",
    "            tokens1 = pair[0][0]\n",
    "            tokens2 = pair[1][0]\n",
    "        else:\n",
    "            tokens1 = pair[0]\n",
    "            tokens2 = pair[1]\n",
    "        output[index] = compute_jaccard_similarity(tokens1, tokens2)\n",
    "        index += 1\n",
    "    return output      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = compute_pair_comparison(train_output, tags)\n",
    "test_results = compute_pair_comparison(test_output, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results\n",
      "[0.53333333 0.38888889 0.31818182 ... 1.         0.55555556 0.375     ]\n",
      "\n",
      "Test results\n",
      "[0.31818182 0.28       0.47826087 ... 0.06666667 0.3        0.46153846]\n"
     ]
    }
   ],
   "source": [
    "print('Train results')\n",
    "print(train_results)\n",
    "print('\\nTest results')\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that:\n",
    "- blabla\n",
    "- blabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with the gold standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the Pearson correlation with the gold standard for the two sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results\n",
      "0.4764116359483076\n",
      "\n",
      "Test results\n",
      "0.4384096557413677\n"
     ]
    }
   ],
   "source": [
    "print('Train results')\n",
    "print(pearsonr(train_labels, train_results)[0])\n",
    "print('\\nTest results')\n",
    "print(pearsonr(test_labels, test_results)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these results we can say that:\n",
    "- blabla\n",
    "- blabla"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
